{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "from collections import defaultdict, Counter\n",
    "\n",
    "import librosa\n",
    "from tqdm.notebook import tqdm\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import albumentations as A\n",
    "from albumentations.core.transforms_interface import DualTransform, BasicTransform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "if torch.cuda.is_available():\n",
    "    dev = \"cuda:0\"\n",
    "    num_workers = 1\n",
    "    pin_memory = True\n",
    "else:\n",
    "    dev = \"cpu\"\n",
    "    num_workers = 0\n",
    "    pin_memory = False\n",
    "num_workers = 0\n",
    "pin_memory = False"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "root_dir = '../slices'"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "data": {
      "text/plain": "   Unnamed: 0  fold                filename  classID\n0           0     1  102106-3-0-0.wav_0.npy        3\n1           1     1  102106-3-0-0.wav_1.npy        3\n2           2     1  102305-6-0-0.wav_0.npy        6\n3           3     1  102305-6-0-0.wav_1.npy        6\n4           4     1  102305-6-0-0.wav_2.npy        6",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Unnamed: 0</th>\n      <th>fold</th>\n      <th>filename</th>\n      <th>classID</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>1</td>\n      <td>102106-3-0-0.wav_0.npy</td>\n      <td>3</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>1</td>\n      <td>102106-3-0-0.wav_1.npy</td>\n      <td>3</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2</td>\n      <td>1</td>\n      <td>102305-6-0-0.wav_0.npy</td>\n      <td>6</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>3</td>\n      <td>1</td>\n      <td>102305-6-0-0.wav_1.npy</td>\n      <td>6</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>4</td>\n      <td>1</td>\n      <td>102305-6-0-0.wav_2.npy</td>\n      <td>6</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "slice_df = pd.read_csv(\"../slice_filenames.csv\")\n",
    "slice_df.head()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "class SignalDataset(Dataset):\n",
    "    def __init__(self, slice_df):\n",
    "        self.slice_df = slice_df\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.slice_df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        row = self.slice_df.iloc[idx,:]\n",
    "        filename = row['filename']\n",
    "        fold = row['fold']\n",
    "        x = np.load(os.path.join(root_dir, f\"fold{fold}\", filename))\n",
    "        x = torch.tensor(x, device=dev).float().unsqueeze(0)\n",
    "        y = torch.tensor(row['classID'], device=dev)\n",
    "        return x, y"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "class AudioTransform(BasicTransform):\n",
    "    \"\"\"Transform for Audio task\"\"\"\n",
    "\n",
    "    @property\n",
    "    def targets(self):\n",
    "        return {\"data\": self.apply}\n",
    "\n",
    "    def update_params(self, params, **kwargs):\n",
    "        if hasattr(self, \"interpolation\"):\n",
    "            params[\"interpolation\"] = self.interpolation\n",
    "        if hasattr(self, \"fill_value\"):\n",
    "            params[\"fill_value\"] = self.fill_value\n",
    "        return params\n",
    "\n",
    "class NoiseInjection(AudioTransform):\n",
    "    \"\"\"It simply add some random value into data by using numpy\"\"\"\n",
    "    def __init__(self, always_apply=False, p=0.5):\n",
    "        super(NoiseInjection, self).__init__(always_apply, p)\n",
    "\n",
    "    def apply(self, data, noise_levels=(0, 0.5), **params):\n",
    "        sound, sr = data\n",
    "        noise_level = np.random.uniform(*noise_levels)\n",
    "        noise = np.random.randn(len(sound))\n",
    "        augmented_sound = sound + noise_level * noise\n",
    "        # Cast back to same data type\n",
    "        augmented_sound = augmented_sound.astype(type(sound[0]))\n",
    "\n",
    "        return augmented_sound, sr\n",
    "\n",
    "class PitchShift(AudioTransform):\n",
    "    \"\"\"Shifting time axis\"\"\"\n",
    "    def __init__(self, always_apply=False, p=0.5):\n",
    "        super(PitchShift, self).__init__(always_apply, p)\n",
    "\n",
    "    def apply(self, data, **params):\n",
    "        sound, sr = data\n",
    "\n",
    "        n_steps = np.random.randint(-10, 10)\n",
    "        augmented_sound = librosa.effects.pitch_shift(sound, sr, n_steps)\n",
    "\n",
    "        return augmented_sound, sr"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "class SignalDataset(Dataset):\n",
    "    def __init__(self, slice_df, do_augment=True):\n",
    "        self.slice_df = slice_df\n",
    "        self.do_augment = do_augment\n",
    "        self.augment = A.Compose([\n",
    "            NoiseInjection(p=0.5),\n",
    "            PitchShift(p=0.5),\n",
    "        ])\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.slice_df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        row = self.slice_df.loc[idx,:]\n",
    "        filename = row['filename']\n",
    "        fold = row['fold']\n",
    "        x = np.load(os.path.join(root_dir, f\"fold{fold}\", filename))\n",
    "        if self.do_augment:\n",
    "            x = self.augment(data=(x, 44100))\n",
    "            x = x['data'][0]\n",
    "        x = torch.tensor(x, device=dev).float().unsqueeze(0)\n",
    "        y = torch.tensor(row['classID'], device=dev)\n",
    "        return x, y"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "train_df = slice_df[(slice_df['fold'] != 8) & (slice_df['fold'] != 9)].reset_index(drop=True)\n",
    "test_df = slice_df[(slice_df['fold'] == 8) | (slice_df['fold'] == 9)].reset_index(drop=True)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [],
   "source": [
    "train_ds = SignalDataset(train_df)\n",
    "test_ds = SignalDataset(test_df)\n",
    "train_dl = DataLoader(train_ds, batch_size=512)\n",
    "test_dl = DataLoader(test_ds, batch_size=512)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [],
   "source": [
    "class SignalModel(nn.Module):\n",
    "    def __init__(self, n_channels=32):\n",
    "        super(SignalModel, self).__init__()\n",
    "        self.relu = nn.ReLU()\n",
    "        self.log_softmax = nn.LogSoftmax(dim=2)\n",
    "        self.conv1 = nn.Conv1d(1, n_channels, kernel_size=240, stride=16)\n",
    "        self.bn1 = nn.BatchNorm1d(n_channels)\n",
    "        self.pool1 = nn.MaxPool1d(4)\n",
    "        self.conv2 = nn.Conv1d(n_channels, n_channels, kernel_size=3)\n",
    "        self.bn2 = nn.BatchNorm1d(n_channels)\n",
    "        self.pool2 = nn.MaxPool1d(4)\n",
    "        self.conv3 = nn.Conv1d(n_channels, 2 * n_channels, kernel_size=3)\n",
    "        self.bn3 = nn.BatchNorm1d(2 * n_channels)\n",
    "        self.pool3 = nn.MaxPool1d(4)\n",
    "        self.conv4 = nn.Conv1d(2 * n_channels, 2 * n_channels, kernel_size=3)\n",
    "        self.bn4 = nn.BatchNorm1d(2 * n_channels)\n",
    "        self.pool4 = nn.MaxPool1d(4)\n",
    "        self.fc1 = nn.Linear(2 * n_channels, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.relu(self.bn1(x))\n",
    "        x = self.pool1(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.relu(self.bn2(x))\n",
    "        x = self.pool2(x)\n",
    "        x = self.conv3(x)\n",
    "        x = self.relu(self.bn3(x))\n",
    "        x = self.pool3(x)\n",
    "        x = self.conv4(x)\n",
    "        x = self.relu(self.bn4(x))\n",
    "        x = self.pool4(x)\n",
    "        x = F.avg_pool1d(x, x.shape[-1])\n",
    "        x = x.permute(0, 2, 1)\n",
    "        x = self.fc1(x)\n",
    "        return torch.squeeze(x)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [],
   "source": [
    "def train(dataloader, model, loss_fn, optimizer, do_augment=True, update_params=True, print_loss=False):\n",
    "    for (image, label) in dataloader:\n",
    "        # Compute prediction and loss\n",
    "        model.train()\n",
    "        pred = model(image)\n",
    "        loss = loss_fn(pred, label)\n",
    "\n",
    "        if(update_params):\n",
    "            # Backpropagation\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "        if(print_loss):\n",
    "            print(loss.item())\n",
    "\n",
    "def avg_acc(model, dataloader):\n",
    "    total_incorrect = 0\n",
    "    num_samples = 0.0\n",
    "    softmax = nn.LogSoftmax(dim=1)\n",
    "    with torch.no_grad():\n",
    "        for image, label in dataloader:\n",
    "            pred = torch.argmax(softmax(model(image)), dim=1)\n",
    "            total_incorrect += torch.count_nonzero(label - pred).item()\n",
    "            num_samples += len(label)\n",
    "    return 1 - (total_incorrect / num_samples)\n",
    "\n",
    "def train_loop(train_dataloader, val_dataloader, model, loss_fn, optimizer, do_augment=True, n_epochs=10):\n",
    "    for _ in range(n_epochs):\n",
    "        train(train_dataloader, model, loss_fn, optimizer)\n",
    "        print(avg_acc(model, val_dataloader))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.17501317870321564\n"
     ]
    }
   ],
   "source": [
    "model = SignalModel().to(device=dev)\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.01, weight_decay=0.001)\n",
    "train_loop(train_dl, test_dl, model, loss_fn, optimizer, n_epochs=1)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [],
   "source": [
    "def full_training_schedule(train_dl, test_dl, model, do_augment=True):\n",
    "    loss_fn = nn.CrossEntropyLoss()\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=0.01, weight_decay=0.001)\n",
    "    train_loop(train_dl, test_dl, model, loss_fn, optimizer, do_augment=do_augment)\n",
    "    for _ in range(3):\n",
    "        optimizer = torch.optim.Adam(model.parameters(), lr=0.001, weight_decay=0.001)\n",
    "        train_loop(train_dl, test_dl, model, loss_fn, optimizer, do_augment=do_augment)\n",
    "    for _ in range(6):\n",
    "        optimizer = torch.optim.Adam(model.parameters(), lr=0.0005, weight_decay=0.001)\n",
    "        train_loop(train_dl, test_dl, model, loss_fn, optimizer, do_augment=do_augment)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Running the full training schedule gave a validation accuracy of 0.40"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [],
   "source": [
    "def get_filename_dict(df):\n",
    "    df['short_filename'] = slice_df['filename'].map(lambda s: str(s).split(\"_\")[0])\n",
    "    filename_dict = defaultdict(list)\n",
    "    for row in df.iterrows():\n",
    "        filename_dict[row[1]['short_filename']] += [row[1]['filename']]\n",
    "    return filename_dict"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [],
   "source": [
    "train_filename_dict = get_filename_dict(train_df)\n",
    "test_filename_dict = get_filename_dict(test_df)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [],
   "source": [
    "class SignalVoteDataset(Dataset):\n",
    "    def __init__(self, slice_df, filename_dict):\n",
    "        self.slice_df = slice_df\n",
    "        self.filename_dict = filename_dict\n",
    "        self.filenames = filename_dict.keys()\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.filename_dict)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        filename = self.filenames[idx]\n",
    "        slice_filenames = self.filename_dict[filename]\n",
    "        x_list, y_list = [], []\n",
    "        for filename in slice_filenames:\n",
    "            row = self.slice_df[self.slice_df['filename'] == filename]\n",
    "            fold = row['fold']\n",
    "            x = np.load(os.path.join(root_dir, f\"fold{fold}\", filename))\n",
    "            x = torch.tensor(x, device=dev).float().unsqueeze(0)\n",
    "            y = torch.tensor(row['classID'], device=dev)\n",
    "            x_list += [x]\n",
    "            y_list += [y]\n",
    "        return torch.stack(x), torch.stack(y)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [],
   "source": [
    "def avg_acc_vote(model, dataloader, df):\n",
    "    total_correct = 0\n",
    "    num_samples = 0.0\n",
    "    softmax = nn.LogSoftmax(dim=1)\n",
    "    filename_dict = get_filename_dict(df)\n",
    "    with torch.no_grad():\n",
    "        last_idx = 0\n",
    "        df['pred'] = np.zeros(len(df))\n",
    "        for image, label in dataloader:\n",
    "            pred = torch.argmax(softmax(model(image)), dim=1)\n",
    "            batch_size = image.shape[0]\n",
    "            print(last_idx, batch_size, len(df['pred'][last_idx:last_idx+batch_size]), len(pred.cpu().numpy()))\n",
    "            df['pred'][last_idx:last_idx+batch_size] = pred.cpu().numpy()\n",
    "            last_idx += batch_size\n",
    "    for filename in filename_dict:\n",
    "        df_rows = df[df['short_filename'] == filename]\n",
    "        votes = df_rows['pred']\n",
    "        vote_counts = Counter(votes)\n",
    "        vote = sorted(vote_counts.items(), key=lambda item: item[1], reverse=True)[0][0]\n",
    "        total_correct += 1 if (vote == df_rows['classID'].iloc[0]) else 0\n",
    "        num_samples += 1\n",
    "    return total_correct / num_samples"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 512 512 512\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-19-4dd60a91896d>:13: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['pred'][last_idx:last_idx+batch_size] = pred.cpu().numpy()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "512 512 512 512\n",
      "1024 512 512 512\n",
      "1536 512 512 512\n",
      "2048 512 512 512\n",
      "2560 512 512 512\n",
      "3072 512 512 512\n",
      "3584 210 210 210\n"
     ]
    },
    {
     "data": {
      "text/plain": "0.4530776992936428"
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "avg_acc_vote(model, test_dl, test_df)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Using the voting classifier, the validation accuracy was 0.45"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "pycharm-b2510d49",
   "language": "python",
   "display_name": "PyCharm (Deep Learning)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}